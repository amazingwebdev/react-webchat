<!DOCTYPE html>
<!-- 
    This is a sample HTML file which shows how to use speech in the WebChat.
    1. Build the project: "npm run build"
    2. Start a web server: "npm run start"
    3. Aim your browser at "http://localhost:8000/samples?[parameters as listed below]"

    For ease of testing, several parameters can be set in the query string:
        * s = Direct Line secret, or
        * t = Direct Line token (obtained by calling Direct Line's Generate Token)
        * domain = optionally, the URL of an alternate Direct Line endpoint
        * webSocket = set to 'true' to use WebSocket to receive messages (currently defaults to false)
        * userid, username = id (and optionally name) of bot user
        * botid, botname = id (and optionally name) of bot

    You have a few options for speech recognition available to you. See definition of speechOptions below

-->
<html>
    <head>
        <meta charset="UTF-8" />
        <title>Bot Chat</title>
        <link href="../../botchat.css" rel="stylesheet" />
        
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
	<style>
		.wc-chatview-panel {
			width: 620px;
			height: 800px;
			position: relative;
		}
        .h2{
            font-family: Segoe UI;
        }
	</style>
    <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.9.0/jquery.min.js"></script>

    </head>
    <body>

        <section class="example">
            <p>
                This sample shows the various options for enabling speech recognition and speech synthesis in the WebChat
            </p>
        </section>

        <div id="BotChatGoesHere"></div>

        <script src="../../botchat.js"></script>        
        <!--If you do not want to use Cognitive Services lib, comment out the following line -->
        <script src="../../CognitiveServices.js"></script>
        
        <script>
            var params = BotChat.queryParams(location.search);

            var user = {
                id: params['userid'] || 'userid',
                name: params["username"] || 'username'
                };
            
            var bot = {
                id: params['botid'] || 'botid',
                name: params["botname"] || 'botname'
            };
            
            window['botchatDebug'] = params['debug'] && params['debug'] === "true";

            // // Option 1 : No Speech
            //
            // var speechOptions = null;

            // Option 2 : native browser speech (not supported by all browsers, no speech recognition priming support)
            

            // Note that chrome automatically blocks speech if the html file is loaded from disk. You can run a server locally 
            // or launch chrome (close all the existing chrome browsers) with the following option:
            // chrome.exe --allow-file-access-from-files <sampleHtmlFile>
            // var speechOptions = {
            //     speechRecognizer: new BotChat.Speech.BrowserSpeechRecognizer(),
            //     speechSynthesizer: new BotChat.Speech.BrowserSpeechSynthesizer()
            // }

            // // Option 3 : Cognitive services speech recognition using API key (cross browser, speech priming support)
            //
            var speechOptions = {
                speechRecognizer: new CognitiveServices.SpeechRecognizer( { subscriptionKey: 'YOUR_COGNITIVE_SPEECH_API_KEY' } ),
                
                speechSynthesizer: new CognitiveServices.SpeechSynthesizer( 
                    { 
                        subscriptionKey: 'YOUR_COGNITIVE_SPEECH_API_KEY', 
                        gender: CognitiveServices.SynthesisGender.Female,
                        voiceName: 'Microsoft Server Speech Text to Speech Voice (en-US, JessaRUS)'
                    })
            }

            // // Option 4 : Cognitive services speech recognition using a token (usually generated in a secure backend using your API key)
            //
            // let getToken = () =>{
            //     // Normally this token fetch is done from your secured backend to avoid exposing the api key and this call
            //     // would be to your backend, or to retrieve a token that was served as part of the original page. 
            //     return $.ajax({
            //         url: "https://api.cognitive.microsoft.com/sts/v1.0/issueToken",
            //         beforeSend: function(xhrObj){
            //             xhrObj.setRequestHeader("Ocp-Apim-Subscription-Key","YOUR_COGNITIVE_SPEECH_API_KEY");
            //         },
            //         type: "POST",
            //     })
            // }
            //
            // var speechOptions = {
            //     speechRecognizer: new CognitiveServices.SpeechRecognizer( 
            //         {
            //             fetchCallback: (authFetchEventId) => getToken(),
            //             fetchOnExpiryCallback: (authFetchEventId) => getToken(), 
            //         }
            //     ),
            //     speechSynthesizer: new BotChat.Speech.BrowserSpeechSynthesizer()
            // }

            // Option 5:
            // Your own custom implementations of ISpeechRecognizer and ISpeechSynthesizer

            BotChat.App({
                directLine: {
                    secret: params['s'],
                    token: params['t'],
                    domain: params['domain'],
                    webSocket: params['webSocket'] && params['webSocket'] === "true" // defaults to true
                },
                user: user,
                bot: bot,
                locale: params['locale'],
                resize: 'detect',
                speechOptions: speechOptions,
                // sendTyping: true,    // defaults to false. set to true to send 'typing' activities to bot (and other users) when user is typing
            }, document.getElementById("BotChatGoesHere"));
        </script>
    </body>
</html>